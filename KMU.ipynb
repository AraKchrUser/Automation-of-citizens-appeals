{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KMU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPm+jhQBg214l0WvpVta98n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AraKchrUser/Automation-of-citizens-appeals/blob/master/KMU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KMU\n"
      ],
      "metadata": {
        "id": "u9qtyDQZTHel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install deeppavlov\n",
        "!python -m deeppavlov install squad_bert"
      ],
      "metadata": {
        "id": "Jn1gSYwHKONV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6327905-6d82-457e-9097-97bcf0b6bd44"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 34.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 18.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n",
            "Collecting deeppavlov\n",
            "  Downloading deeppavlov-0.17.2-py3-none-any.whl (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 37.9 MB/s \n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.62.0\n",
            "  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading overrides-2.7.0.tar.gz (4.5 kB)\n",
            "Collecting uvicorn==0.11.7\n",
            "  Downloading uvicorn-0.11.7-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting uvloop==0.14.0\n",
            "  Downloading uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 35.1 MB/s \n",
            "\u001b[?25hCollecting filelock==3.0.12\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting Cython==0.29.14\n",
            "  Downloading Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 45.2 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "  Downloading ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654 kB)\n",
            "\u001b[K     |████████████████████████████████| 654 kB 50.1 MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8\n",
            "  Downloading pymorphy2-0.8-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting sacremoses==0.0.35\n",
            "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
            "\u001b[K     |████████████████████████████████| 859 kB 41.0 MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.1.0\n",
            "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading rusenttokenize-0.0.5-py3-none-any.whl (10 kB)\n",
            "Collecting pytz==2019.1\n",
            "  Downloading pytz-2019.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 43.3 MB/s \n",
            "\u001b[?25hCollecting prometheus-client==0.7.1\n",
            "  Downloading prometheus_client-0.7.1.tar.gz (38 kB)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Collecting pydantic==1.3\n",
            "  Downloading pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 29.3 MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "  Downloading numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 106.9 MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "  Downloading fastapi-0.47.1-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "  Downloading scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 17.9 MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 34.1 MB/s \n",
            "\u001b[?25hCollecting aio-pika==6.4.1\n",
            "  Downloading aio_pika-6.4.1-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 17 kB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 40.1 MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "  Downloading pyTelegramBotAPI-3.6.7.tar.gz (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading aiormq-3.3.1-py3-none-any.whl (28 kB)\n",
            "Collecting yarl\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 49.7 MB/s \n",
            "\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n",
            "  Downloading starlette-0.12.9.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 39.0 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cryptography>=2.8\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 38.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Collecting idna<2.9,>=2.5\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.1.0)\n",
            "Collecting httptools==0.1.*\n",
            "  Downloading httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219 kB)\n",
            "\u001b[K     |████████████████████████████████| 219 kB 36.6 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading pamqp-2.3.0-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.21)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.10.0.2)\n",
            "Collecting multidict>=4.0\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: nltk, overrides, prometheus-client, pytelegrambotapi, sacremoses, starlette\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449922 sha256=acd48da197821b8bbc2bf02d22c85572ec15a106bb5957b04e3368b44581441a\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-py3-none-any.whl size=5603 sha256=b14776e850e1853beab700c0127a6b6ea69b019696bae2ae160204f89c4f7069\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/87/45/bfdacf6c3b8233b6e8d519edcbd1cf297ad5ff5f0bf84bb9c1\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-py3-none-any.whl size=41405 sha256=2d6df121dfa9bd075abaf4973f45034ac36b6e36730b537dca1c2d9db6793c7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/0c/26/59ba285bf65dc79d195e9b25e2ddde4c61070422729b0cd914\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-py3-none-any.whl size=47176 sha256=2686bae6b40ee979cab9fb24f929eedd049492f5950dc6f59855ffda9dbb0381\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/7c/54/8eddf2369ef1b9190e2ee6dc2b40df54b6c65529a38790fdd4\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=8e1034c08fe893ba4650817b8e552974c0f8e63d8a3763b9e30538ce1e724925\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-py3-none-any.whl size=57252 sha256=8c27884f11703577e2c798e4a19e877ea8ee752c4e97b8d796529d37e6d2c44a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/78/be/f57ed5aed7cd222abdb24e3186b5c9f1074184fcc0a295102b\n",
            "Successfully built nltk overrides prometheus-client pytelegrambotapi sacremoses starlette\n",
            "Installing collected packages: multidict, idna, yarl, pamqp, numpy, websockets, uvloop, tqdm, starlette, requests, pytz, pymorphy2-dicts, pydantic, httptools, h11, dawg-python, cryptography, aiormq, uvicorn, scikit-learn, sacremoses, rusenttokenize, ruamel.yaml, pytelegrambotapi, pyopenssl, pymorphy2-dicts-ru, pymorphy2, prometheus-client, pandas, overrides, nltk, h5py, filelock, fastapi, Cython, aio-pika, deeppavlov\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: sacremoses\n",
            "    Found existing installation: sacremoses 0.0.47\n",
            "    Uninstalling sacremoses-0.0.47:\n",
            "      Successfully uninstalled sacremoses-0.0.47\n",
            "  Attempting uninstall: prometheus-client\n",
            "    Found existing installation: prometheus-client 0.13.1\n",
            "    Uninstalling prometheus-client-0.13.1:\n",
            "      Successfully uninstalled prometheus-client-0.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.4.2\n",
            "    Uninstalling filelock-3.4.2:\n",
            "      Successfully uninstalled filelock-3.4.2\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 0.29.27\n",
            "    Uninstalling Cython-0.29.27:\n",
            "      Successfully uninstalled Cython-0.29.27\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-36.0.1 dawg-python-0.7.2 deeppavlov-0.17.2 fastapi-0.47.1 filelock-3.0.12 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 multidict-6.0.2 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 tqdm-4.62.0 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-13 03:39:58.762 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_bert.json'\n",
            "Collecting tensorflow==1.15.5\n",
            "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 967 bytes/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 63.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (2.10.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.43.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.37.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.18.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.7.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=5591d749026b246836cd31fce4cf5b54cef36d65d3322d4249c254f2ddb11c30\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-hz2548pp\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-hz2548pp\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-py3-none-any.whl size=23593 sha256=d2cc2cc2bd461d6fb588567bb303c3150e703c19974493301f6d953944336a63\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ixvind1v/wheels/44/29/b2/ee614cb7f97ba5c2d220029eaede3af4b74331ad31d6e2f4eb\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2\n",
        "!pip install pymorphy2-dicts\n",
        "!pip install DAWG-Python\n",
        "!pip uninstall pandas\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "She-7d3pe1PS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "2c5f0da9-f5de-4d85-b0a3-7e90b8d0160a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.8)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts in /usr/local/lib/python3.7/dist-packages (2.4.393442.3710985)\n",
            "Requirement already satisfied: DAWG-Python in /usr/local/lib/python3.7/dist-packages (0.7.2)\n",
            "Found existing installation: pandas 0.25.3\n",
            "Uninstalling pandas-0.25.3:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/pandas-0.25.3.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/pandas/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled pandas-0.25.3\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2019.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "deeppavlov 0.17.2 requires pandas==0.25.3, but you have pandas 1.3.5 which is incompatible.\u001b[0m\n",
            "Successfully installed pandas-1.3.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oXBvUMvw9xd",
        "outputId": "339c96dd-134b-4cc1-ee28-487d1bf67a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import deeppavlov\n",
        "from deeppavlov import configs\n",
        "from deeppavlov.core.common.file import read_json\n",
        "from deeppavlov.core.commands.infer import build_model\n",
        "from deeppavlov import configs, train_model\n",
        "\n",
        "import pandas as pd\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "pynQjeDfxE9e"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build - FAQ\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/AraKchrUser/Automation-of-citizens-appeals/master/faq.csv\n",
        "model_config = read_json(configs.faq.tfidf_logreg_autofaq)\n",
        "model_config['dataset_reader']['data_path'] = 'faq.csv'\n",
        "model_config['dataset_reader']['data_url'] = None\n",
        "# model_config['train'] = OrderedDict([('class_name', 'fit_trainer'), ('metrics', ['accuracy']), ('train_score', ['accuracy'])])\n",
        "faq = train_model(model_config);"
      ],
      "metadata": {
        "id": "6ZCG7ifXwZue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46fed280-1f7b-4b1e-acf9-593d2a95640a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "2022-02-13 03:43:36.720 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 219: Cannot load model from /root/.deeppavlov/models/vectorizer/tfidf_vectorizer_ruwiki_v2.pkl\n",
            "2022-02-13 03:43:36.722 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 166: Initializing model sklearn.feature_extraction.text:TfidfVectorizer from scratch\n",
            "2022-02-13 03:43:36.732 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.text:TfidfVectorizer\n",
            "2022-02-13 03:43:36.745 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /root/.deeppavlov/models/vectorizer/tfidf_vectorizer_ruwiki_v2.pkl\n",
            "2022-02-13 03:43:36.750 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/faq/ru_mipt_answers.dict]\n",
            "2022-02-13 03:43:36.753 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 219: Cannot load model from /root/.deeppavlov/models/faq/tfidf_logreg_classifier_v2.pkl\n",
            "2022-02-13 03:43:36.755 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 166: Initializing model sklearn.linear_model:LogisticRegression from scratch\n",
            "2022-02-13 03:43:36.761 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model:LogisticRegression\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "2022-02-13 03:43:36.773 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /root/.deeppavlov/models/faq/tfidf_logreg_classifier_v2.pkl\n",
            "2022-02-13 03:43:36.833 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /root/.deeppavlov/models/vectorizer/tfidf_vectorizer_ruwiki_v2.pkl\n",
            "2022-02-13 03:43:36.836 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
            "2022-02-13 03:43:36.841 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
            "2022-02-13 03:43:36.847 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/faq/ru_mipt_answers.dict]\n",
            "2022-02-13 03:43:36.850 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /root/.deeppavlov/models/faq/tfidf_logreg_classifier_v2.pkl\n",
            "2022-02-13 03:43:36.857 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
            "2022-02-13 03:43:36.859 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
            "2022-02-13 03:43:36.916 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /root/.deeppavlov/models/vectorizer/tfidf_vectorizer_ruwiki_v2.pkl\n",
            "2022-02-13 03:43:36.918 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
            "2022-02-13 03:43:36.920 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
            "2022-02-13 03:43:36.923 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/faq/ru_mipt_answers.dict]\n",
            "2022-02-13 03:43:36.926 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /root/.deeppavlov/models/faq/tfidf_logreg_classifier_v2.pkl\n",
            "2022-02-13 03:43:36.928 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
            "2022-02-13 03:43:36.930 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov.metrics.accuracy import sets_accuracy\n",
        "sets_accuracy(pd.read_csv('faq.csv')['Answer'], faq(pd.read_csv('faq.csv')['Question'])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SivGFoicKUEG",
        "outputId": "30b4fa9f-980c-45e2-c57d-b9e7ce282c31"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squad = build_model(configs.squad.squad_ru_rubert, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaNT6yX8KfV6",
        "outputId": "1c52e6b4-f1b8-4bd2-e159-dd6bf63dbab3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/cryptography/hazmat/backends/openssl/x509.py:17: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
            "  utils.DeprecatedIn35,\n",
            "2022-02-13 03:43:47.659 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/squad_model_ru_rubert.tar.gz to /root/.deeppavlov/squad_model_ru_rubert.tar.gz\n",
            "100%|██████████| 659M/659M [00:32<00:00, 20.4MB/s]\n",
            "2022-02-13 03:44:20.858 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/squad_model_ru_rubert.tar.gz archive into /root/.deeppavlov/models\n",
            "2022-02-13 03:44:31.47 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz to /root/.deeppavlov/downloads/rubert_cased_L-12_H-768_A-12_v1.tar.gz\n",
            "100%|██████████| 666M/666M [00:33<00:00, 19.9MB/s]\n",
            "2022-02-13 03:45:05.451 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/downloads/rubert_cased_L-12_H-768_A-12_v1.tar.gz archive into /root/.deeppavlov/downloads/bert_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:81: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:178: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:154: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:166: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:89: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_squad.py:94: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-02-13 03:45:47.328 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/squad_ru_bert/model_rubert]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/squad_ru_bert/model_rubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build - NER\n",
        "ner_model = build_model(configs.ner.ner_ontonotes_bert_mult, download=True)"
      ],
      "metadata": {
        "id": "eI03gYx_Wcou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8149330-5845-4abb-9f9d-870617c3ec2c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/cryptography/hazmat/backends/openssl/x509.py:17: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
            "  utils.DeprecatedIn35,\n",
            "2022-02-13 03:45:50.461 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_bert_mult_v1.tar.gz to /root/.deeppavlov/ner_ontonotes_bert_mult_v1.tar.gz\n",
            "100%|██████████| 1.32G/1.32G [01:07<00:00, 19.5MB/s]\n",
            "2022-02-13 03:46:59.114 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/ner_ontonotes_bert_mult_v1.tar.gz archive into /root/.deeppavlov/models\n",
            "2022-02-13 03:47:18.881 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip to /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip\n",
            "100%|██████████| 663M/663M [00:33<00:00, 19.8MB/s]\n",
            "2022-02-13 03:47:53.372 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n",
            "2022-02-13 03:48:01.306 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes_bert_mult/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-02-13 03:48:57.450 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_ontonotes_bert_mult/model]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes_bert_mult/model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization(tokens):\n",
        "  norm_tokens = []\n",
        "  if isinstance(tokens, str):\n",
        "    tokens = tokens.split()\n",
        "  for token in tokens:\n",
        "    norm_tokens.append(morph.parse(token)[0].normal_form)\n",
        "  return ' '.join(norm_tokens)"
      ],
      "metadata": {
        "id": "R1BkjJeoMzwn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text, tokens=('B-FAC', 'I-FAC')):\n",
        "  res = ner_model([text])\n",
        "  tkn_1, tkn_2 = tokens\n",
        "  value = list()\n",
        "\n",
        "  slice_ind = 0\n",
        "  slice_len = 1\n",
        "  entity = res[1][0]\n",
        "  token = res[0][0]\n",
        "\n",
        "  i = 0\n",
        "  while i < len(res[1][ 0]):\n",
        "    if entity[i] == tkn_1:\n",
        "      slice_ind = i\n",
        "      slice_len = 1\n",
        "      i += 1\n",
        "      while i != len(res[1][ 0]) and entity[i] == tkn_2:\n",
        "        slice_len += 1\n",
        "        i += 1\n",
        "      value.append(normalization(token[slice_ind: slice_ind + slice_len]))\n",
        "    i += 1\n",
        "  return value\n",
        "\n",
        "text = \"\"\"Введут ли работы на ул. Фрунзе 123 и на пер. Студенческой 12 в г. Благовещенске?\"\"\"\n",
        "preprocess(text, ('B-FAC', 'I-FAC'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuOENVuCCEgF",
        "outputId": "c0e3e8aa-8334-42e6-fb11-afe199b23a46"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ул . фрунзе 123', 'переть . студенческий 12']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2tLUcce9FKR8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(morph.parse('Фетисова')[0].normal_form)\n",
        "# print(morph.parse('Фетисовой')[0].normal_form)\n",
        "# print(morph.parse('Загородную')[0].normal_form)"
      ],
      "metadata": {
        "id": "PlqtWfn5fNxq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7U7cEocZAwyl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/AraKchrUser/Automation-of-citizens-appeals/master/db.csv\n",
        "data = pd.read_csv('db.csv', sep=';')"
      ],
      "metadata": {
        "id": "SNyZR-FJUkDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d520801b-6bf8-4894-ea39-7abf3004cd54"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-13 03:50:41--  https://raw.githubusercontent.com/AraKchrUser/Automation-of-citizens-appeals/master/db.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 803 [text/plain]\n",
            "Saving to: ‘db.csv’\n",
            "\n",
            "db.csv              100%[===================>]     803  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-13 03:50:41 (23.2 MB/s) - ‘db.csv’ saved [803/803]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt1 = \"\"\"110-112 будет установлено 8 лавочек, 6 качелей, 2 детских игровых комплексов, \n",
        "1 карусель, 144 квадратных метра плитки, 67 метра леерного ограждения.\"\"\"\n",
        "txt2 = \"\"\" будет установлено 10 лавочек, 5 качелей, 1 детский игровой комплекс, \n",
        "3 карусели, 123 квадратных метра плитки, 44 метра леерного ограждения.\"\"\""
      ],
      "metadata": {
        "id": "As1QoZ_iaTXn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xmq6Y6SBaTTP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['proj'] = None\n",
        "data.iloc[0, -1] = txt1\n",
        "data.iloc[2, -1] = txt2\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "AOkd2ugvawtt",
        "outputId": "875cc854-103a-457f-ca19-b48062f07efe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4a062793-1e32-46da-b639-912652351e31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>город</th>\n",
              "      <th>адрес</th>\n",
              "      <th>статус</th>\n",
              "      <th>сроки</th>\n",
              "      <th>proj</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Тында</td>\n",
              "      <td>Студенческая 21</td>\n",
              "      <td>в реализации</td>\n",
              "      <td>12.12.22 - 01.02.23</td>\n",
              "      <td>110-112 будет установлено 8 лавочек, 6 качелей...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Благовещенск</td>\n",
              "      <td>Пушкина-Колотушкина 165</td>\n",
              "      <td>в реализации</td>\n",
              "      <td>10.10.22 - 01.02.23</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Сковородино</td>\n",
              "      <td>Светителя 123</td>\n",
              "      <td>в реализации</td>\n",
              "      <td>09.09.22 - 01.02.23</td>\n",
              "      <td>будет установлено 10 лавочек, 5 качелей, 1 де...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Благовещенск</td>\n",
              "      <td>Ленина 12</td>\n",
              "      <td>закрыта</td>\n",
              "      <td>08.08.22 - 01.02.23</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Тында</td>\n",
              "      <td>Армена 007</td>\n",
              "      <td>в реализации</td>\n",
              "      <td>07.07.22 - 01.02.23</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Шимановск</td>\n",
              "      <td>Русская 69</td>\n",
              "      <td>закрыта</td>\n",
              "      <td>06.06.22 - 01.02.23</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Вожаевка</td>\n",
              "      <td>Японская 666</td>\n",
              "      <td>закрыта</td>\n",
              "      <td>05.05.22 - 01.02.23</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Благовещенск</td>\n",
              "      <td>Фрунзе 109</td>\n",
              "      <td>закрыта</td>\n",
              "      <td>04.04.22 - 01.02.23</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Благовещенск</td>\n",
              "      <td>Фетисова 120</td>\n",
              "      <td>в реализации</td>\n",
              "      <td>03.03.22 - 01.02.23</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a062793-1e32-46da-b639-912652351e31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a062793-1e32-46da-b639-912652351e31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a062793-1e32-46da-b639-912652351e31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          город  ...                                               proj\n",
              "0         Тында  ...  110-112 будет установлено 8 лавочек, 6 качелей...\n",
              "1  Благовещенск  ...                                               None\n",
              "2   Сковородино  ...   будет установлено 10 лавочек, 5 качелей, 1 де...\n",
              "3  Благовещенск  ...                                               None\n",
              "4         Тында  ...                                               None\n",
              "5     Шимановск  ...                                               None\n",
              "6      Вожаевка  ...                                               None\n",
              "7  Благовещенск  ...                                               None\n",
              "8  Благовещенск  ...                                               None\n",
              "\n",
              "[9 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_oE6Lesdawqi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J1JAmyTTawea"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kfuMTlSwvqeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greeting():\n",
        "  print('/start', 'Привет \\U0001F44B, чем я могу помочь?', sep='\\n')\n",
        "  print('Если хочешь задать конкретный вопрос о наполняемости конкретной дворовой территории введи знак ➕ на клавиатуре, как закончишь ➖')\n",
        "\n",
        "\n",
        "def fill_street(question, context):\n",
        "  street = preprocess(question, tokens=('B-FAC', 'I-FAC'))\n",
        "  if street:\n",
        "      context['street'] = address_prepr(street[0])\n",
        "\n",
        "\n",
        "def fill_city(question, context): \n",
        "  city = preprocess(question, tokens=('B-GPE', 'I-GPE'))\n",
        "  if city:\n",
        "    context['city'] = city[0]\n",
        "\n",
        "\n",
        "def check_city(context):\n",
        "  while not context['city']:\n",
        "    print('Вы не ввели город \\U0001F609')\n",
        "    question = input()\n",
        "    fill_city(question, context)\n",
        "\n",
        "def check_street(context):\n",
        "  while not context['street']:\n",
        "    print('Вы не ввели улицу \\U0001F64F')\n",
        "    question = input()\n",
        "    fill_street(question, context)\n",
        "    \n",
        "\n",
        "\n",
        "def address_prepr(text):\n",
        "  text = text.replace('улица', '').strip()\n",
        "  text = text.replace('ул.', '').strip()\n",
        "  return text\n",
        "\n",
        "\n",
        "\n",
        "context = {'city': None, 'street': None}\n",
        "data['norm_address'] = data['адрес'].apply(normalization).apply(lambda x: x.replace('-', ' - ').strip())\n",
        "data['norm_city'] = data['город'].apply(normalization)\n",
        "text = ''\n",
        "quary = ''\n",
        "\n",
        "\n",
        "def main():\n",
        "  dialog = True\n",
        "  greeting()\n",
        "\n",
        "  while dialog:\n",
        "\n",
        "    question = input()\n",
        "    if question == '/stop':\n",
        "      return\n",
        "    if question == '+':\n",
        "      ## Тут будут конкретные вопросы-ответы о наполняемости  \n",
        "      while question != '-':\n",
        "        question = input()\n",
        "        fill_street(question, context)\n",
        "        fill_city(question, context)\n",
        "        check_city(context)\n",
        "        check_street(context)\n",
        "        quary = data[data['norm_city'] == context['city']]\n",
        "        text = quary[quary['norm_address'] == context['street']]['proj'].values.tolist()\n",
        "        if text:\n",
        "          print(squad(text, [question])[0][0])\n",
        "        else:\n",
        "          print('Двор не участвует в программе')\n",
        "        \n",
        "    \n",
        "    fill_street(question, context)\n",
        "    fill_city(question, context)\n",
        "  \n",
        "    state, threshold = faq([question])\n",
        "\n",
        "    state = state[0]\n",
        "    threshold = not all(np.array(threshold[0]) < 0.5)\n",
        "\n",
        "    if not threshold:\n",
        "      print('Кто такой Илон Маск, говоришь?')\n",
        "    elif state == 'state1':\n",
        "      check_city(context)\n",
        "      check_street(context)\n",
        "      if context['street'] in data[data['norm_city'] == context['city']]['norm_address'].tolist():\n",
        "        print('Двор участвует в программе')\n",
        "      else:\n",
        "        print('Двор не участвует в программе')\n",
        "    elif state == 'state2':\n",
        "      check_city(context)\n",
        "      check_street(context)\n",
        "      strt = data[data['norm_city'] == context['city']]\n",
        "      strt = strt[strt['norm_address'] == context['street']]['сроки'].values\n",
        "      if strt:\n",
        "        print(\"Сроки реализации данного двора: \", strt[0])\n",
        "      else:\n",
        "        print(\"Двор не участвует в программе\")\n",
        "    elif state == 'state3':\n",
        "      print('Я насчитал в базе', len(pd.unique(data['norm_address'])), 'дворов')"
      ],
      "metadata": {
        "id": "ImShW7kidNex"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np0UN3TX_xMX",
        "outputId": "913a3246-65f6-4c64-a604-b962a7641aab"
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/start\n",
            "Привет 👋, чем я могу помочь?\n",
            "Если хочешь задать конкретный вопрос о наполняемости конкретной дворовой территории введи знак ➕ на клавиатуре, как закончишь ➖\n",
            "+\n",
            "Сколько качелей будет на улице Студенческая 21 в Тынде?\n",
            "6\n",
            "Сколько метров плитки будет проложено?\n",
            "144 квадратных метра\n",
            "Будет ли ограждение?\n",
            "67 метра леерного ограждения\n",
            "Сколько лавочек будет в Сковородино?\n",
            "Двор не участвует в программе\n",
            "Сколько лавочек будет на Светителя 123 в Сковородино?\n",
            "10\n",
            "-\n",
            "\n",
            "Кто такой Илон Маск, говоришь?\n",
            "Нет, подскажи, сколько дворов участвует в программе?\n",
            "Я насчитал в базе 9 дворов\n",
            "Когда закончатся работы на дворе по улице Ленина 12 в Благовещенске?\n",
            "Сроки реализации данного двора:  08.08.22 - 01.02.23\n",
            "Участвует в программе улица Японская 666 в Вожаевке?\n",
            "Двор участвует в программе\n",
            "А участвует ли в программе улица Японская 999?\n",
            "Двор не участвует в программе\n",
            "/stop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quary = data[data['norm_city'] == context['city']]\n",
        "quary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "0s6Enjdld2wu",
        "outputId": "3a0ad39a-b2e8-4c15-90a4-e7d11cfa0d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3b342092-134a-404f-b056-fe7fb59c524b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>город</th>\n",
              "      <th>адрес</th>\n",
              "      <th>статус</th>\n",
              "      <th>сроки</th>\n",
              "      <th>norm_address</th>\n",
              "      <th>norm_city</th>\n",
              "      <th>proj</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Тында</td>\n",
              "      <td>Студенческая 21</td>\n",
              "      <td>в реализации</td>\n",
              "      <td>12.12.22 - 01.02.23</td>\n",
              "      <td>студенческий 21</td>\n",
              "      <td>тында</td>\n",
              "      <td>110-112 будет установлено 8 лавочек, 6 качелей...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Тында</td>\n",
              "      <td>Армена 007</td>\n",
              "      <td>в реализации</td>\n",
              "      <td>07.07.22 - 01.02.23</td>\n",
              "      <td>армен 007</td>\n",
              "      <td>тында</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b342092-134a-404f-b056-fe7fb59c524b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b342092-134a-404f-b056-fe7fb59c524b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b342092-134a-404f-b056-fe7fb59c524b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   город  ...                                               proj\n",
              "0  Тында  ...  110-112 будет установлено 8 лавочек, 6 качелей...\n",
              "4  Тында  ...                                               None\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = quary[quary['norm_address'] == context['street']]['proj']\n",
        "text.value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2i0UNvyd5rO",
        "outputId": "342e2767-d900-490f-eea4-ba592f769355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    110-112 будет установлено 8 лавочек, 6 качелей...\n",
              "Name: proj, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faq(['Участвует двор на улице Японская 666 в Вожаевке в программе?'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g1nMbuWiYSL",
        "outputId": "eb6ff96a-1017-4bf9-bb7b-fe9193132964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['state1'],\n",
              " [[0.7923871256607374,\n",
              "   0.006429901927371733,\n",
              "   0.1980862487628603,\n",
              "   0.003096723649030567]]]"
            ]
          },
          "metadata": {},
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## !!< Баг!"
      ],
      "metadata": {
        "id": "xopJnZs7iylW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faq(['Сколько качелей будет установлено в Тынде на улице Студенческая 21?'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crVmamYNdZHB",
        "outputId": "392a3c43-996e-4413-a4e6-cde4913bd0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['state3'],\n",
              " [[0.0009557733961661296,\n",
              "   0.025371147100208224,\n",
              "   0.9298621232677957,\n",
              "   0.04381095623582994]]]"
            ]
          },
          "metadata": {},
          "execution_count": 351
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9Rh_9dZadxAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fAHGVtSgdLo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vsCASb-rDni1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7a7RdOw1MfKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1VMmsmYHv0v",
        "outputId": "ba712a51-1fa7-46f8-cafa-f8e5f8142b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/start\n",
            "Привет 👋, чем я могу помочь?\n",
            "Привет, подскажи, участвует ли двор на улице Ленина 145 в программе?\n",
            "Вы не ввели город 😉\n",
            "Давай Благовещенск\n",
            "Вы не ввели город 😉\n",
            "Благовещенск\n",
            "Двор не участвует в программе\n",
            "участвует ли двор на улице Ленина 12 в программе?\n",
            "Двор участвует в программе\n",
            "Участвует ли в программе улица Студенческая 21?\n",
            "Двор не участвует в программе\n",
            "Участвует ли в программе улица Студенческая 21  в Тынде?\n",
            "Двор участвует в программе\n",
            "Сколько дворов участвует в программе?\n",
            "9\n",
            "Когда закончится обустройство на Студенческой 21?\n",
            "студенческий 21 :  12.12.22 - 01.02.23\n",
            "Когда закончатся работы на улице Фрунзе 109 в Благовещенске?\n",
            "фрунзе 109 :  04.04.22 - 01.02.23\n",
            "/stop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "APQB10bmIQhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gXqw-ZMlIAx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"На Ленина 110-112 будет установлено 8 лавочек, 6 качелей, 2 детских игровых комплексов, \n",
        "1 карусель, 144 квадратных метра плитки, 67 метра леерного ограждения.\"\"\"\n",
        "squad([text], ['Сколько будет установлено качелей во дворе на улице Ленина 196?'])[0][0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mv-i2PLjLjUh",
        "outputId": "b5b160e0-3cc6-40a8-ddab-e2ba2ae56a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'6'"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[36:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jAEhlR8ALoKa",
        "outputId": "70b75937-ab2e-4267-8ca8-023240f11534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'8 лавочек, 6 качелей, 2 детских игровых комплексов, \\n1 карусель, 144 квадратных метра плитки, 67 метра леерного ограждения.'"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state, threshold = faq([question])"
      ],
      "metadata": {
        "id": "oMCzsF9BT7UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te7J4CU-WuqM",
        "outputId": "265afb31-ba6c-4c91-8c7d-0ee04856cafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.004134446011396008,\n",
              "  0.9767034124644673,\n",
              "  0.005428488541833146,\n",
              "  0.013733652982303614]]"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4_Oa0ADaWvip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}